python RAG/llama_get_activations.py --model_name llama2_chat_7B --dataset_name nq --nq_jsonl RAG/data/train.jsonl --use_chat_template

python RAG/nq_train_save_probes.py --model_name llama2_chat_7B --top_k 24 --seed 2025 --num_fold 5 --cv_final_train full

python RAG/nq_generate_with_interventions.py --model_name llama2_chat_7B --dataset_path RAG/data/test.jsonl --use_chat_template --alpha 15 --top_heads_path results_dump/probes/llama2_chat_7B_nq_seed_2025_top_24_folds_5_top_heads.pkl --probes_path results_dump/probes/llama2_chat_7B_nq_seed_2025_top_24_folds_5_probes.pkl --val_accs_path results_dump/probes/llama2_chat_7B_nq_seed_2025_top_24_folds_5_val_accs.npy --tuning_headwise_path features/llama2_chat_7B_nq_head_wise.npy --sample_size 30 --sample_seed 2025 --max_new_tokens 256

top-k alpha EM(RAG) F1(RAG) EM(interventions) F1(interventions)
24 15 0.43333333333333335 0.5474490244055461 0.1 0.29398768513858026
24 10 0.43333333333333335 0.5474490244055461  0.2 0.36727801607664307
24 5 0.43333333333333335 0.5474490244055461 0.36666666666666664 0.48713926009578185



python RAG/llama_get_activations.py --model_name llama2_chat_7B --dataset_name nq --nq_jsonl RAG/data/train.jsonl --use_chat_template

python RAG/nq_train_save_probes.py --model_name llama2_chat_7B --top_k 12 --seed 2025 --num_fold 5 --cv_final_train full

python RAG/nq_generate_with_interventions.py --model_name llama2_chat_7B --dataset_path RAG/data/test.jsonl --use_chat_template --alpha 15 --top_heads_path results_dump/probes/llama2_chat_7B_nq_seed_2025_top_12_folds_5_top_heads.pkl --probes_path results_dump/probes/llama2_chat_7B_nq_seed_2025_top_12_folds_5_probes.pkl --val_accs_path results_dump/probes/llama2_chat_7B_nq_seed_2025_top_12_folds_5_val_accs.npy --tuning_headwise_path features/llama2_chat_7B_nq_head_wise.npy --sample_size 30 --sample_seed 2025 --max_new_tokens 256

top-k alpha EM(RAG) F1(RAG) EM(interventions) F1(interventions)
12 15 0.43333333333333335 0.5474490244055461 0.0 0.1760108695968442
12 10 0.43333333333333335 0.5474490244055461  0.06666666666666667 0.2644052057782035
12 5 0.43333333333333335 0.5474490244055461 0.26666666666666666 0.4005784898384845


python RAG/llama_get_activations.py --model_name llama2_chat_7B --dataset_name nq --nq_jsonl RAG/data/train.jsonl --use_chat_template

python RAG/nq_train_save_probes.py --model_name llama2_chat_7B --top_k 36 --seed 2025 --num_fold 5 --cv_final_train full

python RAG/nq_generate_with_interventions.py --model_name llama2_chat_7B --dataset_path RAG/data/test.jsonl --use_chat_template --alpha 15 --top_heads_path results_dump/probes/llama2_chat_7B_nq_seed_2025_top_36_folds_5_top_heads.pkl --probes_path results_dump/probes/llama2_chat_7B_nq_seed_2025_top_36_folds_5_probes.pkl --val_accs_path results_dump/probes/llama2_chat_7B_nq_seed_2025_top_36_folds_5_val_accs.npy --tuning_headwise_path features/llama2_chat_7B_nq_head_wise.npy --sample_size 30 --sample_seed 2025 --max_new_tokens 256

top-k alpha EM(RAG) F1(RAG) EM(interventions) F1(interventions)
36 15 0.43333333333333335 0.5474490244055461 0.06666666666666667 0.26693793000668203
36 10 0.43333333333333335 0.5474490244055461  0.2 0.36474194506231117
36 5 0.43333333333333335 0.5474490244055461 0.3333333333333333 0.4536852460275624
36 20 0.43333333333333335 0.5474490244055461 0.0 0.14118668626408565


python RAG/llama_get_activations.py --model_name llama2_chat_7B --dataset_name nq --nq_jsonl RAG/data/train.jsonl --use_chat_template

python RAG/nq_train_save_probes.py --model_name llama2_chat_7B --top_k 36 --seed 2025 --num_fold 5 --cv_final_train full

python RAG/nq_generate_with_interventions.py --model_name llama2_chat_7B --dataset_path RAG/data/test.jsonl --use_chat_template --alpha 15 --top_heads_path results_dump/probes/llama2_chat_7B_nq_seed_2025_top_64_folds_5_top_heads.pkl --probes_path results_dump/probes/llama2_chat_7B_nq_seed_2025_top_64_folds_5_probes.pkl --val_accs_path results_dump/probes/llama2_chat_7B_nq_seed_2025_top_64_folds_5_val_accs.npy --tuning_headwise_path features/llama2_chat_7B_nq_head_wise.npy --sample_size 50 --sample_seed 2025 --max_new_tokens 256

top-k alpha EM(RAG) F1(RAG) EM(interventions) F1(interventions)
36 15 0.43333333333333335 0.5474490244055461 0.06666666666666667 0.26693793000668203
36 10 0.43333333333333335 0.5474490244055461  0.2 0.36474194506231117
36 5 0.43333333333333335 0.5474490244055461 0.3333333333333333 0.4536852460275624
36 20 0.43333333333333335 0.5474490244055461 0.0 0.14118668626408565
